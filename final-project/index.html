<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta
            name="viewport"
            content="width=device-width, initial-scale=1, shrink-to-fit=no" />

        <!-- Bootstrap CSS -->
        <link
            href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css"
            rel="stylesheet"
            integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH"
            crossorigin="anonymous" />

        <link href="style.css" rel="stylesheet" />
    </head>

    <body>
        <div class="container-fluid body-image">
            <div class="row">
                <div class="col">
                    <img src="Screen Shot 2024-04-22 at 11.42.21 AM.png" />
                </div>
            </div>
            <div class="row">
                <div class="col">
                    <p class="caption">
                        Illustration
                        <span class="credit"> Mark Harris/The Guardian</span>
                    </p>
                </div>
            </div>
            <div class="row">
                <div class="col">
                    <h1>
                        Weizenbaum’s Nightmares: How the inventor of the first
                        chatbot turned against AI
                    </h1>
                </div>
            </div>
        </div>
        <div class="container-fluid content">
            <div class="row">
                <div class="col">
                    <h2>
                        Computer scientist Joseph Weizenbaum was there at the
                        dawn of artificial intelligence – but he was also
                        adamant that we must never confuse computers with
                        humans.
                    </h2>
                    <h3>By Ben Tarnoff</h3>
                    <h3>July 25, 2023</h3>
                    <h7>First Creation</h7>
                    <h5>
                        In 1966, an MIT professor named Joseph Weizenbaum
                        created the first chatbot. He cast it in the role of a
                        psychotherapist. A user would type a message on an
                        electric typewriter connected to a mainframe. After a
                        moment, the “psychotherapist” would reply.
                    </h5>
                </div>
            </div>
            <div class="row">
                <div class="col">
                    <h4>User: Men are all alike.</h4>
                    <h4>Chatbot: IN WHAT WAY</h4>
                    <h4>
                        User: They’re always bugging us about something or
                        other.
                    </h4>
                    <h4>Chatbot: CAN YOU THINK OF A SPECIFIC EXAMPLE</h4>
                    <h4>User: Well, my boyfriend made me come here.</h4>
                    <h4>Chatbot: YOUR BOYFRIEND MADE YOU COME HERE</h4>
                    <h4>User: He says I’m depressed much of the time.</h4>
                    <h4>Chatbot: I AM SORRY TO HEAR YOU ARE DEPRESSED</h4>
                </div>
            </div>
            <div class="row">
                <div class="col">
                    <h6>
                        Weizenbaum published this sample exchange in a journal
                        article that explained how the chatbot worked. The
                        software was relatively simple. It looked at the user
                        input and applied a set of rules to generate a plausible
                        response. He called the program Eliza, after Eliza
                        Doolittle in Pygmalion. The cockney flower girl in
                        George Bernard Shaw’s play uses language to produce an
                        illusion: she elevates her elocution to the point where
                        she can pass for a duchess. Similarly, Eliza would speak
                        in such a way as to produce the illusion that it
                        understood the person sitting at the typewriter.
                    </h6>
                </div>
            </div>
            <div class="row">
                <div class="col">
                    <h6>
                        “Some subjects have been very hard to convince that
                        Eliza (with its present script) is not human,”
                        Weizenbaum wrote. In a follow-up article that appeared
                        the next year, he was more specific: one day, he said,
                        his secretary requested some time with Eliza. After a
                        few moments, she asked Weizenbaum to leave the room. “I
                        believe this anecdote testifies to the success with
                        which the program maintains the illusion of
                        understanding,” he noted.
                    </h6>
                </div>
            </div>
            <div class="row">
                <div class="col">
                    <h6>
                        Eliza isn’t exactly obscure. It caused a stir at the
                        time – the Boston Globe sent a reporter to go and sit at
                        the typewriter and ran an excerpt of the conversation –
                        and remains one of the best known developments in the
                        history of computing. More recently, the release of
                        ChatGPT has renewed interest in it. In the last year,
                        Eliza has been invoked in the Guardian, the New York
                        Times, the Atlantic and elsewhere. The reason that
                        people are still thinking about a piece of software that
                        is nearly 60 years old has nothing to do with its
                        technical aspects, which weren’t terribly sophisticated
                        even by the standards of its time. Rather, Eliza
                        illuminated a mechanism of the human mind that strongly
                        affects how we relate to computers.
                    </h6>
                </div>
            </div>
            <div class="row">
                <div class="col">
                    <h6>
                        Early in his career, Sigmund Freud noticed that his
                        patients kept falling in love with him. It wasn’t
                        because he was exceptionally charming or good-looking,
                        he concluded. Instead, something more interesting was
                        going on: transference. Briefly, transference refers to
                        our tendency to project feelings about someone from our
                        past on to someone in our present. While it is amplified
                        by being in psychoanalysis, it is a feature of all
                        relationships. When we interact with other people, we
                        always bring a group of ghosts to the encounter. The
                        residue of our earlier life, and above all our
                        childhood, is the screen through which we see one
                        another.
                    </h6>
                </div>
            </div>
            <div class="row">
                <div class="col">
                    <h6>
                        This concept helps make sense of people’s reactions to
                        Eliza. Weizenbaum had stumbled across the computerised
                        version of transference, with people attributing
                        understanding, empathy and other human characteristics
                        to software. While he never used the term himself, he
                        had a long history with psychoanalysis that clearly
                        informed how he interpreted what would come to be called
                        the “Eliza effect”.
                    </h6>
                </div>
            </div>
            <div class="row">
                <div class="col">
                    <h6>
                        As computers have become more capable, the Eliza effect
                        has only grown stronger. Take the way many people relate
                        to ChatGPT. Inside the chatbot is a “large language
                        model”, a mathematical system that is trained to predict
                        the next string of characters, words, or sentences in a
                        sequence. What distinguishes ChatGPT is not only the
                        complexity of the large language model that underlies
                        it, but its eerily conversational voice. As Colin
                        Fraser, a data scientist at Meta, has put it, the
                        application is “designed to trick you, to make you think
                        you’re talking to someone who’s not actually there”.
                    </h6>
                </div>
            </div>
            <div class="row">
                <div class="col">
                    <h6>
                        But the Eliza effect is far from the only reason to
                        return to Weizenbaum. His experience with the software
                        was the beginning of a remarkable journey. As an MIT
                        professor with a prestigious career, he was, in his
                        words, a “high priest, if not a bishop, in the cathedral
                        to modern science”. But by the 1970s, Joseph Weizenbaum
                        had become a heretic, publishing articles and books that
                        condemned the worldview of his colleagues and warned of
                        the dangers posed by their work. Artificial
                        intelligence, he came to believe, was an “index of the
                        insanity of our world.”
                    </h6>
                </div>
            </div>
            <div class="row">
                <div class="col">
                    <h6>
                        Today, the view that artificial intelligence poses some
                        kind of threat is no longer a minority position among
                        those working on it. There are different opinions on
                        which risks we should be most worried about, but many
                        prominent researchers, from Timnit Gebru to Geoffrey
                        Hinton – both ex-Google computer scientists – share the
                        basic view that the technology can be toxic.
                        Weizenbaum’s pessimism made him a lonely figure among
                        computer scientists during the last three decades of his
                        life; he would be less lonely in 2023.
                    </h6>
                </div>
            </div>
            <div class="row">
                <div class="col">
                    <h6>
                        There is so much in Weizenbaum’s thinking that is
                        urgently relevant now. Perhaps his most fundamental
                        heresy was the belief that the computer revolution,
                        which Weizenbaum not only lived through but centrally
                        participated in, was actually a counter-revolution. It
                        strengthened repressive power structures instead of
                        upending them. It constricted rather than enlarged our
                        humanity, prompting people to think of themselves as
                        little more than machines. By ceding so many decisions
                        to computers, he thought, we had created a world that
                        was more unequal and less rational, in which the
                        richness of human reason had been flattened into the
                        senseless routines of code.
                    </h6>
                </div>
            </div>
            <div class="row">
                <div class="col">
                    <h6>
                        Weizenbaum liked to say that every person is the product
                        of a particular history. His ideas bear the imprint of
                        his own particular history, which was shaped above all
                        by the atrocities of the 20th century and the demands of
                        his personal demons. Computers came naturally to him.
                        The hard part, he said, was life.
                    </h6>
                </div>
            </div>
            <div class="row">
                <div class="col"></div>
            </div>
        </div>
        <div class="container-fluid body-image">
            <div class="row">
                <div class="col">
                    <img src="first computer.png" />
                </div>
            </div>
        </div>
        <div class="container-fluid">
            <div class="row">
                <div class="col">
                    <p class="caption">
                        Eniac, one of the world’s first electronic digital
                        computers, circa 1945.
                        <span class="credit">Photograph: Corbis/Getty</span>
                    </p>
                </div>
            </div>
        </div>
        <div class="container-fluid content">
            <div class="row">
                <div class="col">
                    <h6>
                        What it means to be human – and how a human is different
                        from a computer – was something Weizenbaum spent a lot
                        of time thinking about. So it’s fitting that his own
                        humanity was up for debate from the start. His mother
                        had a difficult labour, and felt some disappointment at
                        the result. “When she was finally shown me, she thought
                        I was a bloody mess and hardly looked human,” Weizenbaum
                        later recalled. “She couldn’t believe this was supposed
                        to be her child.”
                    </h6>
                </div>
            </div>
        </div>
    </body>
</html>
